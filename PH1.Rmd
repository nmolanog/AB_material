---
title: "Introducción a las Pruebas de hipótesis"
author: "Nicolás Molano Gonzalez"
date: "18 de Septiembre de 2018"
output: 
  html_document:
    fig_caption: true
---
```{r echo=F, message = FALSE, warning =F}
rm(list=ls())
list.of.packages <- c("pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(pacman)
p_load(datasets)
p_load(tidyverse)
p_load(kableExtra)
p_load(knitr)
p_load(MASS)
p_load(boot)
p_load(carData)   
p_load(ggbeeswarm)

tex2markdown <- function(texstring) {
  writeLines(text = texstring,
             con = myfile <- tempfile(fileext = ".tex"))
  texfile <- pandoc(input = myfile, format = "html")
  cat(readLines(texfile), sep = "\n")
  unlink(c(myfile, texfile))
}
set.seed(150)


```

En este documento introducimos los conceptos básicos al rededor de las pruebas de hipótesis. En resumen las pruebas de hipótesis se usan para probar hipótesis estadísticas acerca de parámetros poblacionales. Veamos un ejemplo

# Estudio metformina + glibenclamida

Un investigador quiere determinar si el tratamiento metformina + glibenclamida funciona, es decir reduce la glucosa en sangre (*glu*) en una población de indígenas del Amazonas. Para esto, con ayuda de un estadístico, se ha diseñado un experimento en donde a una muestra de 100 indígenas de esta población se les hace dos mediciones de *glu*: una primera medición antes de aplicar el medicamento y otra  medición después de aplicarlo. Con estos datos de _pre-post_, se calcula la resta de la segunda medición menos la primera. A continuación presentamos como se ven los datos en una tabla:

```{r echo=FALSE, results = 'asis'}
n<-100
mu_pre<-145
sd_pre<-7.5
sd_post<-3.3
pre<-rnorm(n,mu_pre,sd_pre)
post<-rnorm(n,100,sd_post)
data_pre_post1<-data.frame(Pre=pre,Post=post,Dif=post-pre)
kable_styling(kable(head(data_pre_post1,10)),"striped", position = "center")
```

Para estudiar el efecto del medicamento en la *glu* desde un punto de vista estadístico, pensemos en la distribución poblacional de la diferencia _post-pre_, en particular en su valor esperado. Sea $Dif= Post-Pre$. Existen tres posibilidades para $E(Dif)$:

```{r , echo=F, fig.width=14, fig.height=5}
sd_dif<-sqrt(7.5^2+3.3^2)
p1<-ggplot(data = data.frame(x = c(-50,60)), aes(x)) + ylab("f(Dif)")+xlab("Dif")+
  stat_function(fun = dnorm, args = list(mean = -15,sd=sd_dif),color="green")+
  stat_function(fun = dnorm, args = list(mean = 0,sd=sd_dif),color="blue")+
  stat_function(fun = dnorm, args = list(mean = 15,sd=sd_dif),color="red")+
  annotate("text", x = rep(50,3), y = seq(.05,.04,length.out = 3), 
           label = c("E(Dif)<0","E(Dif)=0","E(Dif)>0") , size=4 , 
           color=c("green","blue","red"))+
  theme_bw()

p2<-ggplot(data = data.frame(x = c(-40,20)), aes(x)) + ylab("f(Dif)")+xlab("Dif")+
  stat_function(fun = dnorm, args = list(mean = -15,sd=sd_dif))+
  geom_segment(aes(x=0,xend=0,y=0,yend=dnorm(0,-15,sd_dif)),color="red")+
  stat_function(fun = dnorm, args = list(mean=-15,sd=sd_dif),
                xlim = c(0,20),
                geom = "area",fill="red",alpha=0.5)+
  annotate("segment", x = 3, xend = 9, y =.002 , yend = .02, colour = "red", size=1, alpha=0.6, arrow=arrow())+
  annotate("text", x = c(10), y = c(.022), 
           label = "Patients with Dif > 0",size=4 , fontface="bold")+
  annotate("segment", x = -10, xend = -3, y =.03 , yend = .04, colour = "red", size=1, alpha=0.6, arrow=arrow())+
  annotate("text", x = c(-2), y = c(.042), 
           label = "Patients with Dif < 0",size=4 , fontface="bold")+
  theme_bw()
gridExtra::grid.arrange(grobs =list(p1,p2),nrow=1,ncol=2)
```

* Si $E(Dif)=0$ esto implicaría que, en general, el tratamiento no cambia los niveles de glucosa en sangre en la población. Esto no quiere decir que los valores de $Dif$ para todos los pacientes sea 0. Lo que ocurriría en la practica es que existen grupos de pacientes para los cuales el medicamento disminuye los niveles de *glu* (es decir $Dif<0$) y para otros aumentaría (es decir $Dif>0$). Parecería que el medicamento funciona aleatoriamente reduciendo o aumentando la *glu* en la población. Ante un comportamiento tan impredecible llegaríamos a la conclusión que el medicamento no funciona.

* Si $E(Dif)<0$ esto implicaría que existe un gran numero de pacientes para los cuales el medicamento produjo una disminución de *glu*. Aunque puedan existir pacientes para los cuales $Dif>0$, es decir que se produjo un aumento de *glu* después de aplicar el tratamiento, este porcentaje de pacientes seria mucho menor que el de aquellos en los que hubo una reducción (es decir $Dif<0$).

* De forma similar sucedería con $E(Dif)<0$

Entonces, es claro que dependiendo del valor de $E(Dif)$ en relación al valor de comparación $0$, se podría concluir acerca de la eficacia del medicamento. Sin embargo, $E(Dif)$ es desconocido y la única forma que tenemos para aproximarnos a su verdadero valor es la información obtenida a partir de la muestra. A continuación presentamos tres muestras obtenidas de las tres posibles distribuciones anteriormente mostradas para $Dif$:

## Caso 1

A continuación presentamos una muestra de la población en donde $E(Dif)=0$.

```{r , echo=F, fig.width=14, fig.height=5}
post1<-pre+rnorm(n,0,sd_post)
sample_dif1<-data.frame(Pre=pre,Post=post1,Dif=post1-pre)

sample_dif1%>%gather()%>%mutate(key=factor(key,levels=c("Pre","Post","Dif")))%>%ggplot(aes(x=value))+
  geom_histogram(aes(y = ..density..),bins=10,color="black",fill="grey")+
  facet_wrap(~key, scales = "free")+xlab("glu")+theme_bw()


```


```{r , echo=F, fig.width=6, fig.height=4}
sample_dif1%>%summary
```

Vemos que el valor promedio del *glu* _pre_ es `r sample_dif1$Pre %>% mean%>% round(3)`, el valor promedio de *glu* _post_ es `r sample_dif1$Post %>% mean%>% round(3)` y la diferencia promedio es `r sample_dif1$Dif %>% mean%>% round(3)`. Con estos datos, podríamos pensar que $E(Dif)$ esta muy cerca de 0 y que por ende el medicamento no seria efectivo. 

Que herramienta podríamos usar para saber que tan cerca estaría $E(Dif)$ de 0 en base a la información de la muestra? Podríamos calcular el intervalo de 95% de confianza para $E(Dif)$ y ver si el valor de 0 cae en ese intervalo. 

Ejercicio: Calcule el intervalo de 95% de confianza para $E(Dif)$ usando la siguiente información: $n=$ `r n`; $\overline{Dif}=$ `r sample_dif1$Dif %>% mean%>% round(3)`; $S=$ `r sample_dif1$Dif %>% sd%>% round(3)`; usar los cuantiles $t_{99,0.025}=$ `r qt(0.025,99)` y $t_{99,0.975}=$ `r qt(0.975,99)`.

Al hacer los cálculos determinamos que el intervalo de confianza es: 

```{r , echo=F, fig.width=6, fig.height=4}
sample_dif1$Dif%>%t.test()%>%{c(.$conf.int[1],.$conf.int[2])}
```
Claramente, 0 esta en el intervalo de confianza. Otro dato mas que apoyaría la _hipótesis_ de que $E(Dif)=0$.

Otra forma de visualizar los datos e inspeccionar que tanta diferencia hay entre las medidas _pre_ y _post_ en un boxplot:

```{r , echo=F, fig.width=5, fig.height=3.4}

sample_dif1%>%gather()%>%filter(!key %in% "Dif") %>%
  mutate(key=factor(key,levels=c("Pre","Post")))%>%
  ggplot(aes(x=key,y=value))+
  geom_boxplot()+
 geom_beeswarm(priority='density',cex=2.5)+
  ylab("glu")+theme_bw()

```

De nuevo vemos evidencia de la nula diferencia entre las medidas _pre_ y _post_

##Caso 2
Ahora presentamos una muestra de la población en donde $E(Dif)>0$.

```{r , echo=F, fig.width=10, fig.height=8}
post2<-pre+rnorm(n,10,sd_post)
sample_dif2<-data.frame(Pre=pre,Post=post2,Dif=post2-pre)

p1<-sample_dif2%>%gather()%>%mutate(key=factor(key,levels=c("Pre","Post","Dif")))%>%ggplot(aes(x=value))+
  geom_histogram(aes(y = ..density..),bins=10,color="black",fill="grey")+
  facet_wrap(~key, scales = "free")+xlab("glu")+theme_bw()

p2<-sample_dif2%>%gather()%>%filter(!key %in% "Dif") %>%
  mutate(key=factor(key,levels=c("Pre","Post")))%>%
  ggplot(aes(x=key,y=value))+
  geom_boxplot()+
 geom_beeswarm(priority='density',cex=2.5)+
  ylab("glu")+theme_bw()
gridExtra::grid.arrange(grobs =list(p1,p2),layout_matrix=matrix(c(1,1,1,1,3,2,2,4),byrow = T,nrow=2))

```


```{r , echo=F, fig.width=6, fig.height=4}
sample_dif2%>%summary
```

Analizando toda la información es claro que el medicamento aumenta la _glu_. Calculemos el intervalo de 95% confianza: $n=$ `r n`; $\overline{Dif}=$ `r sample_dif2$Dif %>% mean%>% round(3)`; $S=$ `r sample_dif2$Dif %>% sd%>% round(3)`; usamos los cuantiles $t_{99,0.025}=$ `r qt(0.025,99)` y $t_{99,0.975}=$ `r qt(0.975,99)`.

Al hacer los cálculos determinamos que el intervalo de confianza es: 
```{r , echo=F, fig.width=6, fig.height=4}
sample_dif2$Dif%>%t.test()%>%{c(.$conf.int[1],.$conf.int[2])}
```
Claramente, el intervalo de confianza esta por encima de 0 y no tendríamos dudas de que el medicamento aumenta la _glu_.

##Caso 3
Ahora presentamos una muestra de la población en donde $E(Dif)<0$.

```{r , echo=F, fig.width=10, fig.height=8}
post3<-pre+rnorm(n,-3,7)
sample_dif3<-data.frame(Pre=pre,Post=post3,Dif=post3-pre)

p1<-sample_dif3%>%gather()%>%mutate(key=factor(key,levels=c("Pre","Post","Dif")))%>%ggplot(aes(x=value))+
  geom_histogram(aes(y = ..density..),bins=10,color="black",fill="grey")+
  facet_wrap(~key, scales = "free")+xlab("glu")+theme_bw()

p2<-sample_dif3%>%gather()%>%filter(!key %in% "Dif") %>%
  mutate(key=factor(key,levels=c("Pre","Post")))%>%
  ggplot(aes(x=key,y=value))+
  geom_boxplot()+
 geom_beeswarm(priority='density',cex=2.5)+
  ylab("glu")+theme_bw()
gridExtra::grid.arrange(grobs =list(p1,p2),layout_matrix=matrix(c(1,1,1,1,3,2,2,4),byrow = T,nrow=2))

```


```{r , echo=F, fig.width=6, fig.height=4}
sample_dif3%>%summary
```

Analizando toda la información **no es tan claro** que el medicamento disminuya la _glu_, en particular la disminución es apenas perceptible, la diferencia promedio es de apenas `r sample_dif3$Dif %>% mean%>% round(3)`. Calculemos el intervalo de 95% confianza: $n=$ `r n`; $\overline{Dif}=$ `r sample_dif3$Dif %>% mean%>% round(3)`; $S=$ `r sample_dif3$Dif %>% sd%>% round(3)`; usamos los cuantiles $t_{99,0.025}=$ `r qt(0.025,99)` y $t_{99,0.975}=$ `r qt(0.975,99)`.

Al hacer los cálculos determinamos que el intervalo de confianza es: 
```{r , echo=F, fig.width=6, fig.height=4}
sample_dif3$Dif%>%t.test()%>%{c(.$conf.int[1],.$conf.int[2])}
```
El intervalo de confianza esta por debajo de 0 indicando que efectivamente $E(Dif)<0$. Sin embargo la evidencia gráfica no nos deja tan convencidos.

##Prueba de hipótesis
Ya que necesitamos una forma objetiva de tomar una decisión frente a la relación que pueda tener $E(Dif)$ con el valor de referencia $0$, desarrollaremos la prueba de hipótesis.

Supongamos que nos interesa demostrar que el medicamento cambia la *glu* sin importar si logra un aumento o disminución. Es decir que nos enteriza demostrar que $E(Dif)\neq 0$. Entonces se plantea el siguiente sistema de hipótesis:
$$H_{0}: E(Dif)=0$$
$$H_{a}: E(Dif) \neq 0$$
$H_0$ y $H_a$ se conocen como hipótesis nula y alternativa respectivamente (mas adelante brindaremos mas detalles acerca de esto). 

Ya que estamos hablando acerca del valor esperado, recordemos al estadístico $T$ cuya formula es: 
$$T_{n-1}=\frac{\sqrt(n)\Big(\overline{Dif}-E(Dif)\Big)}{S}$$
Donde

* $\overline{Dif}$ es el promedio calculado con la muestra.
* $S$ es la desviación estándar calculada con la muestra.
* $n$ es el tamaño de la muestra y $\sqrt{n}$ su raíz cuadrada.
* $E(Dif)$ es el valor esperado de $Dif$

Y cuya distribución no depende de $E(Dif)$ si no de el tamaño de la muestra $n$.

```{r , echo=F, fig.width=6, fig.height=4}
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  stat_function(fun = dt, args = list(df = 70),color="blue")+ylab("f(t)")+xlab("t")+
  stat_function(fun = dt, args = list(df = 35),color="green")+
  stat_function(fun = dt, args = list(df = 10),color="orange")+
  stat_function(fun = dt, args = list(df = 5),color="red")+
  annotate("text", x = rep(1.7,4), y = seq(.39,.31,length.out = 4), 
           label = paste0("GL = ",c(70,35,10,5)) , size=4 , 
           color=c("blue","green","orange","red"))+
  theme_bw()
```

Anteriormente nuca fuimos capases de calcular el estadístico $T$ con los datos de la muestra, ya que en la formula, teníamos toda la información salvo $E(Dif)$, el parámetro poblacional, que precisamente queríamos estimar, y para el cual usamos el estadístico $T$ con el fin de calcular el intervalo de confianza. Sin embargo, si asumimos que la hipótesis nula es cierta entonces $E(Dif)=0$ y tendríamos todos los valores para calcular el estadístico $T$.

A continuación presentamos los valores del estadístico calculados para las tres muestras antes analizadas. (Ejercicio: verifique los cálculos).

```{r echo=FALSE, results = 'asis'}
dif_list<-list(s1=sample_dif1$Dif,s2=sample_dif2$Dif,s3=sample_dif3$Dif)
t_df<-data.frame(Caso=1:3,t_obs=dif_list%>%map(~t.test(.))%>%map_dbl(~.$statistic))
t1<-kable(t_df)
kable_styling(t1,"striped", position = "center")

```

La posibilidad de calcular el estadístico $T$ asumiendo el escenario de la hipótesis nula (es decir $E(Dif)=0$) nos permitirá cuantificar que tan probables o compatibles son los datos a la luz de la hipótesis nula. Veamos los estadísticos $t$ calculados en relación con la distribución $T_{99}$:

```{r, echo=F, fig.width=6, fig.height=4}
t_new<-1.86
t_toplot<-c(t_df$t_obs[-2],t_new)
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = list(df = 99),color="blue")+ylab("f(t)")+
  annotate("segment", x = t_toplot, xend = t_toplot, 
           y = rep(0.2,length(t_df$t_obs[-2])+1), yend = rep(0,length(t_df$t_obs[-2])+1), colour = "red", size=.6, alpha=0.6, arrow=arrow())+
  annotate("text", x = t_toplot+.4, y = rep(0.22,3), 
           label = paste0(c("s1: t= ","s3: t= ", "t= "),round(t_toplot,2)), size=4 , fontface="bold")+
  theme_bw()
```

Es claro que el estadístico $t$ calculado con la muestra del __caso 1__ (`r round(t_df$t_obs[1],3)`), se encuentra en una zona de alta densidad de probabilidad bajo la distribución del estadístico $T_{99}$. Esta distribución y el estadístico asumen el escenario de la hipótesis nula (es decir $E(Dif)=0$), por lo cual diremos lo siguiente:

* __Ya que el estadístico $t$ observado, calculado con los datos de la muestra, cayo en una zona de alta densidad de probabilidad, bajo el escenario de la hipótesis nula, concluimos que los datos son altamente compatibles con el escenario de la hipótesis nula __

Es decir, el hecho que el valor del estadístico $t$ observado se encuentre un una zona de alta densidad de probabilidad indicaría que la hipótesis nula $H_{0}: E(Dif)=0$ no podria descartarse.

En contraste el estadístico $t$ calculado con la muestra del __caso 2 y 3__ (`r round(t_df$t_obs[2:3],3)`), se encuentran en zonas de muy baja densidad de probabilidad bajo la distribución del estadifico $T_{99}$, por lo cual diremos lo siguiente:

* __Ya que el estadístico $t$ observado, calculado con los datos de la muestra, cayo en una zona de baja densidad de probabilidad, bajo el escenario de la hipótesis nula, concluimos que los datos _NO_ son compatibles con el escenario de la hipótesis nula __

Es decir, el hecho que el valor del estadístico $t$ observado se encuentre un una zona de baja densidad de probabilidad indicaría que la hipótesis nula $H_{0}: E(Dif)=0$ **puede descartarse** y la única alternativa restante seria $H_{a}: E(Dif) \neq 0$.

Pero que pensaríamos si el valor del estadístico observado fuera `r round(t_new,3)`? abría gente que pensaría que ese valor esta en una región de baja probabilidad pero para otras persona, esa región no tiene una probabilidad despreciable. En esta situación se hace difícil tomar una decisión acerca de la plausibilidad de los datos bajo el escenario de la hipótesis nula.

###Limites de Aceptacion y Rechazo

Ya que juzgar si el estaditico de prueba observado (EPO de aque en adelante) se encuentra en una zona de alta o baja probabilidad se hace subjetivo, debemos establecer una regla objetiva para determinar si el EPO se encuentra en una zona de alta o baja probabilidad, es decir, si se acepta o se rechaza la hipotesis nula.

Para esto, denuevo, usaremos los cuantiles de la distribucion $T$. Defineremos dos cuantiles que acumulen una cantidad de probabilidad deseable como $1-\alpha$ (esto se parece a algo!!) y EPOs por fuera de estos dos cuantiles seran considerados como evidencia en contra de la hipotesis nula. Por ejemplo, si $\alpha=0.05$ entonces $1-\alpha=0.95$ y , de nuevo, usaremos los cuantiles $t_{n-1,\alpha/2}$ y $t_{n-1,1-\alpha/2}$
```{r, echo=F, fig.width=14, fig.height=4}
gl<-30
p1<-ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = list(df = 30))+ylab("f(t)")+
  geom_segment(aes(x=qt(.975,gl),xend=qt(.975,gl),y=0,yend=dt(qt(.975,gl),gl)))+
  geom_segment(aes(x=qt(.025,gl),xend=qt(.025,gl),y=0,yend=dt(qt(.025,gl),gl)))+
  scale_x_continuous("t", round(c(-5,qt(1-.975,gl),0,qt(.975,gl),5),3), limits=c(-5,5))+
  annotate("segment", x = c(-2.2,2.2,0), xend = c(-3.8,3.8,2), 
           y = c(0.02,0.02,.3), yend = c(.16,.16,.35), colour = "red", size=1, alpha=0.6, arrow=arrow())+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(qt(.975,gl),5),
                geom = "area",fill="red",alpha=0.5)+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(-5,qt(.025,gl)),
                geom = "area",fill="red",alpha=0.5)+
  annotate("text", x = c(-3.8,3.8,2.7), y = c(0.18,0.18,.37), 
           label = c("alpha/2","alpha/2","1-alpha"),parse=T , size=4 , fontface="bold")+
  theme_bw()

p2<-ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = list(df = 30))+ylab("f(t)")+
  geom_segment(aes(x=qt(.975,gl),xend=qt(.975,gl),y=0,yend=dt(qt(.975,gl),gl)))+
  geom_segment(aes(x=qt(.025,gl),xend=qt(.025,gl),y=0,yend=dt(qt(.025,gl),gl)))+
  scale_x_continuous("t", round(c(-5,qt(1-.975,gl),0,qt(.975,gl),5),3), limits=c(-5,5))+
  annotate("segment", x = c(-2.2,2.2,0), xend = c(-3.8,3.8,2), 
           y = rep(0,3), yend = c(.16,.16,.35), colour = "red", size=1, alpha=0.6, arrow=arrow())+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(qt(.975,gl),5),
                geom = "area",fill="red",alpha=0.5)+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(-5,qt(.025,gl)),
                geom = "area",fill="red",alpha=0.5)+
  annotate("text", x = c(-3.8,3.8,2.7), y = c(0.18,0.18,.37), 
           label = c("Zona~de~rechazo~H[0]","Zona~de~rechazo~H[0]","Zona~de~aceptacion~H[0]"),parse=T , size=4 , fontface="bold")+
  theme_bw()
gridExtra::grid.arrange(grobs =list(p1,p2),nrow=1,ncol=2)
```

###Error tipo I

Una vez establecidos los limetes de aceptacion y rechazo, debemos caer en cuenta de la posibilidad de equivocarnos en nuestra desicion. Que error podriamos cometer al establecer esta regla de desicion? En primera instancia podriamos rechazar $H_{0}$ cuando esta es en realidad verdadera. Las zonas de baja probabilidad del estadistico $T$ que hemos delimitado con los cauntiles $t_{n-1,\alpha/2}$ y $t_{n-1,1-\alpha/2}$, acumulan en conjunto una probabilidad de $\alpha$, por lo general $\alpha$ es un numero pequeño, al rededor de $0.05$. Esto quiere decir que si $H_0$ es cierta, existe la posibilidad de observar EPO en la zona de rechazo, en concreto la probabilidad de observar esto es de $\alpha=0.05$. De esta forma, y asumiendo que $H_0$ es cierta, con esta regla de desicion la probabilidad de equivocarnos es $\alpha$. El error de rechazar $H_0$ cuando esta es verdadera se llama __Error Tipo I__ y $\alpha$ se conoce como __Nivel de significancia__ y es en realidad la probabilidad de cometer el error tipo I, claro, en el caso en que $H_0$ es verdadera.
$$\alpha=P_{H_0}(Error~Tipo~I)$$

###Vovliendo al ejemplo

Establescamos los limites de aceptacion y rechazo para el caso de nuestro estudio, asumiendo una probabilidad de error tipo I o nivel de significancia $\alpha$ de $0.05$. Debemos encontrar los cuantiles $t_{99,\alpha/2=0.025}$ y $t_{9,1-\alpha/2=0.975}$. Estos tienen los siguientes valores: $t_{99,0.025} =$ `r round(qt(0.025,99),3)` y $t_{99,0.975} =$ `r round(qt(0.975,99),3)`.


```{r, echo=F, fig.width=6, fig.height=4}
gl<-99
s_level<-0.05
t_toplot<-c(t_df$t_obs[-2],t_new)
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = list(df = gl),color="blue")+ylab("f(t)")+
  geom_segment(aes(x=qt(1-(s_level/2),gl),xend=qt(1-(s_level/2),gl),y=0,yend=dt(qt(1-(s_level/2),gl),gl)))+
  geom_segment(aes(x=qt(s_level/2,gl),xend=qt(s_level/2,gl),y=0,yend=dt(qt(s_level/2,gl),gl)))+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(qt(1-(s_level/2),gl),5),
                geom = "area",fill="red",alpha=0.5)+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(-5,qt(s_level/2,gl)),
                geom = "area",fill="red",alpha=0.5)+
  annotate("segment", x = t_toplot[-3], xend = t_toplot[-3], 
           y = rep(0.2,length(t_df$t_obs[-2])), yend = rep(0,length(t_df$t_obs[-2])), colour = "red", size=.6, alpha=0.6, arrow=arrow())+
  annotate("text", x = t_toplot[-3]+.4, y = rep(0.22,2), 
           label = paste0(c("s1: t= ","s3: t= "),round(t_toplot[-3],2)), size=4 , fontface="bold")+
  theme_bw()
```
Para las muestras de los casos 2 y 3 el EPO cae en las zonas de rechazo y por ende $H_0: E(Dif)=0$ se rechaza y queda la hipotesis alternativa como unica opcion $H_a: E(Dif) \neq 0$. Para la muestra del caso 1, el EPO cae en la zona de aceptacion y no se puede rechazar $H_0: E(Dif)=0$.

La interpretacion de estos resultados, es que al rechazar la hipotesis nula mostramos que, segun la informacion de la muestra, $E(Dif) \neq 0$ y por ende el tratamiento cambia de alguna forma (aun por determinar) la _glu_.

###Como plantear sistemas de hipotesis
En el ejemplo anterior, vimos que el sistema de hipotesis empleado fue:

$$H_{0}: E(Dif)= 0$$
$$H_{a}: E(Dif) \neq 0$$

Pero existen 2 sistemas alternativos mas, para un total de 3 posibles sistemas de hipotesis:

```{r echo=FALSE, results = 'asis', message=FALSE}
textable<-"
\\begin{table}[]
\\begin{tabular}{|l|l|l|}
 Caso 1                 & Caso 2               & Caso 3               \\\\ \\hline
 $H_{0}: E(Dif)=0$      & $H_{0}: E(X)\\leq 0$ & $H_{0}: E(X)\\geq 0$ \\\\
 $H_{a}: E(Dif)\\neq 0$ & $H_{a}: E(Dif) > 0$  & $H_{a}: E(Dif) < 0$  \\hline
\\end{tabular}
\\end{table}
"
tex2markdown(textable)
```
Las reglas para generar
