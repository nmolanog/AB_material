---
title: "Intervalos de confianza"
author: "Nicolás Molano Gonzalez"
date: "18 de Septiembre de 2018"
output: 
  html_document:
    fig_caption: true
---
```{r echo=F, message = FALSE, warning =F}
library(datasets)
library(tidyverse)
library(kableExtra)
library(knitr)
library(MASS)
library(boot)
library(carData)   

set.seed(150)
```
En este documento presentamos la teoría y motivación detrás de los intervalos de confianza (IC).

#Motivación

EL punto de partida es la construcción de la siguiente expresionismo:

$$P(L \leq \delta \leq U)=1-\alpha$$
Donde $\delta$ es un parámetro poblacional, como por ejemplo, el valor esperado $E(X)$ o la varianza $V(X)$. Que hay detrás de esta expresión? Básicamente, esta expresión dice lo siguiente:

* La probabilidad de que el parámetro $\delta$ se encuentre entre dos numero $L$ y $U$ es de $1-\alpha$. 

Por ejemplo, si $\alpha=0.05$ estaríamos diciendo que la probabilidad de encontrar al parámetro $\delta$  entre los números $L$ y $U$ es de $1-\alpha=1-0.05=0.95$.

Sin embargo, esto no es posible, ya que el paramento poblacional $\delta$ no es una variable aleatoria, carece de función de densidad y por ende, no podemos calcular probabilidades sobre el. Los estadísticos decimos que $\delta$ es un parámetro fijo y desconocido, no una variable aleatoria.

A pesar de esta imposibilidad técnica, existe una aproximación para llegar a una expresión de este estilo. A continuación presentaremos, como ejemplo el IC para el valor esperado.

#IC para el valor esperado.

Existe una cantidad llamada el "estadístico T de student" el cual se define de la siguiente forma:

$$T_{n-1}=\frac{\sqrt{n}\big(\overline{X}-E(X)\big)}{S}$$

Donde: 

* $X$ es una variable aleatoria cualquiera.
* $n$ es el tamaño de la muestra y $\sqrt{n}$ su raíz cuadrada.
* $\bar{X}$ es el promedio calculado con la muestra.
* $S$ es la desviación estándar calculada con la muestra.
* $E(X)$ es el valor esperado de la variable aleatoria $X$.

Esta cantidad, atribuida a varios autores, popularizada por Ronald Fisher quien le puso el nombre actual de "_T de Student_" debido a un articulo científico publicado en biometrika en 1908, escrito por William Sealy Gosset bajo el seudónimo de "_Student_", tiene ciertas propiedades sumamente interesantes. Primero nótese que las cantidades involucradas en esta formula son obtenidas de datos muéstrales salvo $E(X)$, que es un parámetro desconocido y que por lo general se quiere estimar. Es decir que si tuviéramos los datos de una muestra, no podríamos calcular el estadístico $T_{n-1}$ ya que nos haría falta conocer el valor de $E(X)$. A pesar de la imposibilidad de poder calcular esta cantidad con datos de una muestra, si se sabe algo mucho mas interesante del estadístico $T_{n-1}$: Se conoce su función de densidad (bajo ciertos supuestos acerca de la funcion de densidad de $X$) y esta no depende del valor que tenga $E(X)$. A continuación presentamos su formula:

$$f(t) = \frac{\Gamma\Big(\frac{n}{2}\Big)} {\sqrt{(n-1)\pi}\,\Gamma\big(\frac{n-1}{2}\big)} \left(1+\frac{t^2}{n-1} \right)^{\!-\frac{n}{2}}$$
Es una formula un poco complicada, lo importante es notar que esta formula depende de exclusivamente de $t$ y de $n-1$, es decir que esta función de densidad tiene un único parámetro que es $n-1$ y que se denomina **_grados de libertad_**. Veamos como cambia la función de densidad con diferentes grados de libertad:

```{r , echo=F, fig.width=6, fig.height=4}
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  stat_function(fun = dt, args = list(df = 70),color="blue")+ylab("f(t)")+xlab("t")+
  stat_function(fun = dt, args = list(df = 35),color="green")+
  stat_function(fun = dt, args = list(df = 10),color="orange")+
  stat_function(fun = dt, args = list(df = 5),color="red")+
  annotate("text", x = rep(1.7,4), y = seq(.39,.31,length.out = 4), 
           label = paste0("GL = ",c(70,35,10,5)) , size=4 , 
           color=c("blue","green","orange","red"))+
  theme_bw()
```

Se puede demostrar que $E(T_{n-1})=0$ y que $V(T_{n-1})=\frac{n-1}{n-3}$. Este estadístico $T_{n-1}$ nos deja muy cerca de lo que inicialmente se quería pues, es posible encontrar dos números $L$ y $U$ tal que:

$$P(L \leq T_{n-1} \leq U)=P\left(L \leq \frac{\sqrt{n}\big(\overline{X}-E(X)\big)}{S} \leq U\right)=1-\alpha$$
Por que es posible encontrar estos números $L$ y $U$? porque $T_{n-1}$ tiene una función de densidad conocida, y podemos hallar un par de números, entre los cuales existe una probabilidad (es decir un área bajo la curva) de $1-\alpha$:

```{r , echo=F, fig.width=6, fig.height=4}
gl<-30
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dt, args = list(df = 30))+ylab("f(t)")+
  geom_segment(aes(x=qt(.975,gl),xend=qt(.975,gl),y=0,yend=dt(qt(.975,gl),gl)))+
  geom_segment(aes(x=qt(.025,gl),xend=qt(.025,gl),y=0,yend=dt(qt(.025,gl),gl)))+
  scale_x_continuous("t", round(c(-5,qt(1-.975,gl),0,qt(.975,gl),5),3), limits=c(-5,5))+
  annotate("segment", x = c(-2.2,2.2,0), xend = c(-3.8,3.8,2), 
           y = c(0.02,0.02,.3), yend = c(.16,.16,.35), colour = "red", size=1, alpha=0.6, arrow=arrow())+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(qt(.975,gl),5),
                geom = "area",fill="red",alpha=0.5)+
  stat_function(fun = dt, args = list(df = gl),
                xlim = c(-5,qt(.025,gl)),
                geom = "area",fill="red",alpha=0.5)+
  annotate("text", x = c(-3.8,3.8,2.7), y = c(0.18,0.18,.37), 
           label = c("alpha/2","alpha/2","1-alpha"),parse=T , size=4 , fontface="bold")+
  theme_bw()
``` 

Los números $L$ y $U$ resultan ser los cuantiles $t_{n-1,\alpha/2}$ y $t_{n-1,\alpha/2}$.

Nótese que para el caso de $E(X)$ la expresión a la que deseamos llegar es  $P(L \leq E(X) \leq U)=1-\alpha$ y que la expresión que tenemos hasta el momento es $P\left(t_{n-1,\alpha/2} \leq \frac{\sqrt{n}\big(\overline{X}-E(X)\big)}{S} \leq t_{n-1,\alpha/2}\right)=1-\alpha$.