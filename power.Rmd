---
title: "Potencia y tamaño de muestra"
author: "Nicolás Molano Gonzalez"
date: "18 de Septiembre de 2018"
output: 
  html_document:
    fig_caption: true
---
```{r echo=F, message = FALSE, warning =F}
rm(list=ls())
list.of.packages <- c("pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(pacman)
p_load(tidyverse)
p_load(kableExtra)
p_load(knitr)
p_load(ggbeeswarm)
p_load(latex2exp)
p_load(magick)
tex2markdown <- function(texstring) {
  writeLines(text = texstring,
             con = myfile <- tempfile(fileext = ".tex"))
  texfile <- pandoc(input = myfile, format = "html")
  cat(readLines(texfile), sep = "\n")
  unlink(c(myfile, texfile))
}
set.seed(150)


```
En este documento estudiaremos como el tamaño de muestra afecta la probabilidad de cometer el error tipo II en pruebas de hipótesis. En primera instancia, recordemos que son los errores tipo I y II:

```{r echo=FALSE, results = 'asis', message=FALSE}
textable<-"
\\begin{table}[]
\\begin{tabular}{|l|l|l|}
                        & True $H_0$    & True $H_a$    \\\\ \\hline
 Guess  $H_0$           & True          & Error type II \\\\
 Guess  $H_a$           & Error type I  & True          \\hline
\\end{tabular}
\\end{table}
"
tex2markdown(textable)
```

Para esta discucion, considere el ejemplo anterior del estudio de metformina + glibenclamida. En este estudio nos intereza demostrar que el medicamento disminuye los niveles de glucosa en sangre por lo cual la el valor esperado de $Dif= Post-Pre$ deberia ser menor a sero. El sistema de hipotesis apropiado es el siguiente:
$$H_{0}: E(Dif)\geq 0$$
$$H_{a}: E(Dif) < 0$$
Ya que nos interesa estudiar $E(Dif)$, sabemos que su estimador es el promedio, denotado por $\overline{Dif}$. Adicionalmente sabemos que el promedio, como estimador también es una variable aleatoria y que 
$$E(\overline{Dif})=E(Dif)~~y~~V(\overline{Dif})=V(Dif)/n$$

Esto tiene implicaciones en la calidad de la estimación a medida que el tamaño de muestra aumenta como se ha discutido antes.

```{r , echo=F, fig.width=6, fig.height=4}
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0,sd=4),color="blue")+ylab(TeX("$f(\\bar{Dif})$"))+xlab(TeX("$\\bar{Dif}$"))+
  stat_function(fun = dnorm, args = list(mean = 0,sd=4/sqrt(5)),color="red")+
  stat_function(fun = dnorm, args = list(mean = 0,sd=4/sqrt(25)),color="orange")+
  stat_function(fun = dnorm, args = list(mean = 0,sd=4/sqrt(75)),color="green")+
  annotate("text", x = rep(2.5,4), y = seq(.5,.76,length.out = 4), 
           label = paste0("n = ",c(1,5,25,75)) , size=4 , 
           color=c("blue","red","orange","green"))+
  theme_bw()
```

Sin embargo, se desconoce el verdadero valor de $E(Dif)$ y por esta razón es que se desarrolla la teoría de intervalos de confianza y pruebas de hipótesis. Por un momento supongamos que $E(Dif)=-1.7$. Comparemos la distribución de $\overline{Dif}$ bajo dos escenarios: el de la hipótesis nula y el supuesto anteriormente. Para efectos prácticos asuma que el tamaño de la muestra es de $50$:

```{r , echo=F, fig.width=6, fig.height=4}
f1<-function(x,a,b,c,d){return(dnorm(x,a,b)-dnorm(x,c,d))}
uniroot(f1, c(-2, 0), tol = 0.0001, a = 0,b=4/sqrt(50),c=-1.7,d=4/sqrt(50))$root->cross_point
sd_dif<-4/sqrt(50)
p1<-ggplot(data = data.frame(x = c(-4, 2.7)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0,sd=sd_dif),color="red")+ylab(TeX("$f(\\bar{Dif})$"))+xlab(TeX("$\\bar{Dif}$"))+
  stat_function(fun = dnorm, args = list(mean = -1.7,sd=sd_dif),color="blue")+
  annotate("text", x = rep(2,2), y = seq(.5,.6,length.out = 2), 
           label = paste0("E(Dif) = ",c(0,-1.7)) , size=4 , 
           color=c("red","blue"))+
  theme_bw()

p1+stat_function(fun = dnorm, args = list(mean = 0,sd=4/sqrt(50)),
                xlim = c(-2.5,cross_point),
                geom = "area",fill="grey",alpha=0.5)+
  stat_function(fun = dnorm, args = list(mean = -1.7,sd=4/sqrt(50)),
                xlim = c(cross_point,1),
                geom = "area",fill="grey",alpha=0.5)
```

Nótese que existe una zona de posibles valores bajo ambas distribuciones (área gris). Si se observaran valores promedios de diferencias $Post-Pre$ en este rango, no sabríamos si vienen de una u otra distribución.

Se puede demostrar que existe una correspondencia entre la distribución del estadístico $T_{n-1}$ y la distribución de $\overline{Dif}$ bajo la hipótesis nula (de ahora en adelante $\overline{Dif}_{H_0}$), de tal forma que los cuantiles en la distribución $T_{n-1}$ se relacionan con aquellos en la distribución de $\overline{Dif}_{H_0}$. Así que si fijamos una probabilidad de error tipo I, $\alpha=0.05$ la zona de rechazo equivalente en la distribución de $\overline{Dif}_{H_0}$ es el segmento bajo el área roja:

```{r , echo=F,warning =F, fig.width=6, fig.height=4}
f1<-function(x,a,b,c,d){return(dnorm(x,a,b)-dnorm(x,c,d))}
uniroot(f1, c(-2, 0), tol = 0.0001, a = 0,b=4/sqrt(50),c=-1.7,d=4/sqrt(50))$root->cross_point

p1+geom_segment(aes(x=qnorm(.05,0,sd_dif),xend=qnorm(.05,0,sd_dif),y=0,yend=dnorm(qnorm(.05,0,sd_dif),0,sd_dif)))+
    stat_function(fun = dnorm, args = list(mean = 0,sd=4/sqrt(50)),
                xlim = c(qnorm(.05,0,sd_dif),-2.5),
                geom = "area",fill="red",alpha=0.5)+
      stat_function(fun = dnorm, args = list(mean = -1.7,sd=4/sqrt(50)),
                xlim = c(qnorm(.05,0,sd_dif),1),
                geom = "area",fill="orange",alpha=0.5)+
annotate("segment", x = c(-1.4,-0.7), xend = c(-3.8,1.6), 
           y = c(.005,.005), yend = c(.32,.32), colour = c("red","orange"), size=0.7, alpha=0.6, arrow=arrow(angle=15))+
  annotate("text", x = c(-3.9,1.7), y = c(.32,.32)+.03, 
           label =c(TeX("$\\alpha$"),TeX("$\\beta$"))  , size=4)
```

Por otra parte, el rango de valores en donde podríamos cometer el error tipo II es el  que se encuentra bajo el área naranja. $\beta=P(E.II)=$ `r round(pnorm(qnorm(.05,0,sd_dif),-1.7,sd_dif,lower.tail =F),3)`, que es la medida del área naranja.
Note que $1-\beta$ es la probabilidad de observar valores en la zona de rechazo pero bajo un valor posible de la hipótesis alternativa. Esta probabilidad se denomina la _**POTENCIA**_ de la prueba.

Cuales son los factores que afectan la potencia y por ende, la probabilidad de cometer el error tipo II? Existen dos factores principales: 

1. La magnitud de la diferencia entre el verdadero valor de $E(Dif)$ y el valor asumido en la hipótesis nula.
2. El tamaño de la muestra.

Como se puede apreciar en la siguiente animación, entre mayor sea la diferencia entre el verdadero valor ($H_a:~E(Dif)$) y el de la hipótesis nula ($H_0:~E(Dif)=0$), mayor sera la potencia de la prueba ($1-\beta$) y menor sera la probabilidad de cometer el error tipo 2 ($\beta$).

```{r , echo=F,warning =F, fig.width=6, fig.height=4}
gif1 <- image_read("power.gif") 
gif1
```

Como ya vimos anteriormente, la varianza de $\overline{Dif}$ disminuye con el tamaño de muestra a razón de $1/\sqrt{n}$, de tal forma que la potencia de la prueba aumenta a medida que aumenta el tamaño de la muestra, como se puede apreciar en la siguiente animación:

```{r , echo=F,warning =F, fig.width=6, fig.height=4}
gif2 <- image_read("power2.gif") 
gif2
```

De forma similar la varianza de la población afecta la potencia. Podría usted intuir cual es la relación entre la varianza de la población y la potencia?

# Relación entre el error tipo I y el error tipo II

Ahora discutiremos la relación existente entre los dos tipos de errores, en particular, la imposibilidad de disminuir los dos tipos de error simultáneamente. En primera instancia veamos que sucede con el error tipo II si disminuimos el error tipo I:

```{r , echo=F,warning =F, fig.width=6, fig.height=4}
gif3 <- image_read("power3.gif") 
gif3
```

Se puede apreciar que al disminuir el error tipo I ($\alpha$), el error tipo II ($\beta$) aumenta y de forma reciproca si se disminuye $\beta$, $\alpha$ debe aumentar, fijando el tamaño de muestra.

#Resumen

La potencia de la prueba definida como la probabilidad de no cometer el error tipo II, es decir la probabilidad de rechazar la hipótesis nula cuando esta debe ser rechazada, se ve afectada por múltiples factores:

* La magnitud de la diferencia entre el valor del parámetro en la hipótesis nula y el verdadero valor del parámetro en la población (hipótesis alternativa).
* El tamaño de la muestra
* La varianza poblacional
* El nivel de significancia fijado (probabilidad de error tipo I, $\alpha$)

En la practica la potencia se usa para determinar el tamaño de muestra necesaria para detectar un valor de un parámetro dado. Esto implica que se deben conocer varios elementos de la variable que se estudia, en particular dos:

* El valor del parámetro que se espera detectar
* El valor de la varianza en la población

Estos dos parámetros son claves ya que definen las formas y ubicaciones de las funciones de densidad de los estimadores bajo la hipótesis nula y la alternativa, haciendo posible determinar el tamaño de muestra apropiado para alcanzar una potencia dada.

Sin embargo, en la practica, muchas veces es difícil conocer, sobre todo la varianza de la población, mas aun cuando estamos haciendo un muestreo, precisamente para conocer atributos de la población, entre ellos la varianza. Este problema, se puede principalmente de dos formas:

1. Un valor aproximado de la varianza puede ser obtenido a partir de estudios previos.
2. El valor aproximado de la varianza puede ser obtenido a través de una muestra piloto.

En la primera aproximación, nos basamos en información reportada en la literatura para tener una idea de la magnitud de la varianza en la población. En la segunda aproximación, que se usa por lo general cuando no se dispone de información auxiliar, se realiza un pequeño estudio piloto para tener una primera estimación de la magnitud de la varianza poblacional. 

En cuanto al valor del parámetro que se desa detectar, su valor por lo general estará asociado con efectos prácticos del problema de estudio que se desea abordar. Veamos un ejemplo.


